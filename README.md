# Decoder-LangModel
A simple implementation of a decoder-only Transformer language model with Character-level tokenization, trained from scratch with 10.7M parameters to generate text character by character.
